{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595ad214",
   "metadata": {},
   "source": [
    "# A Real-Time Dengue Map for Singapore\n",
    "- README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9cfe4",
   "metadata": {},
   "source": [
    "## Setup and imports \n",
    "- libraries, path setup\n",
    "- dependencies.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d61b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (0.27.0)\n",
      "Requirement already satisfied: pandas in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: geopandas in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (1.1.1)\n",
      "Collecting folium\n",
      "  Downloading folium-0.20.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting branca\n",
      "  Downloading branca-0.8.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: anyio in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from httpx) (4.6.2)\n",
      "Requirement already satisfied: certifi in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from httpx) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from httpx) (1.0.2)\n",
      "Requirement already satisfied: idna in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from httpx) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from httpx) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages\\pytz-2025.1-py3.11.egg (from pandas) (2025.1)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from geopandas) (24.2)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from geopandas) (3.7.2)\n",
      "Requirement already satisfied: shapely>=2.0.0 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from geopandas) (2.1.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from folium) (3.1.5)\n",
      "Requirement already satisfied: requests in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from folium) (2.32.3)\n",
      "Collecting xyzservices (from folium)\n",
      "  Downloading xyzservices-2025.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from jinja2>=2.9->folium) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\gis_envs\\envs\\arcgispro-ai\\lib\\site-packages (from requests->folium) (2.3.0)\n",
      "Downloading folium-0.20.0-py2.py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  112.6/113.4 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 113.4/113.4 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading branca-0.8.2-py3-none-any.whl (26 kB)\n",
      "Downloading xyzservices-2025.4.0-py3-none-any.whl (90 kB)\n",
      "   ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 90.4/90.4 kB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: xyzservices, branca, folium\n",
      "Successfully installed branca-0.8.2 folium-0.20.0 xyzservices-2025.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install  httpx pandas geopandas folium branca\n",
    "# --- IGNORE --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ada884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Optional, Any, Dict\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3286552",
   "metadata": {},
   "source": [
    "## Data acquisition \n",
    "> Acquire Live Data from APIs\n",
    "- api_config(api sources)\n",
    "- fetch_dengue.py, fetch_weather.py\n",
    "- load_subzoneboundaries, load_populationsubzone\n",
    "- fetch_ndvi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c569d3",
   "metadata": {},
   "source": [
    "api document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b963e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API configuration loaded inline.\n",
      "  • nea: dengue_clusters\n",
      "  • weather: air_temperature, rainfall\n",
      "  • satellite: \n"
     ]
    }
   ],
   "source": [
    "# API configuration\n",
    "api_config: Dict[str, Any] = {\n",
    "    \"nea\": {\n",
    "        \"dengue_clusters\": {\n",
    "            \"dataset_id\": \"d_dbfabf16158d1b0e1c420627c0819168\",\n",
    "            \"base_url\": \"https://api-open.data.gov.sg/v1/public/api/datasets\",\n",
    "            \"description\": \"NEA dengue cluster data - Red (>=10 cases), Yellow (<10 cases), Green (surveillance)\"\n",
    "        }\n",
    "    },\n",
    "    \"weather\": {\n",
    "        \"air_temperature\": {\n",
    "            \"url\": \"https://api-open.data.gov.sg/v2/real-time/api/air-temperature\",\n",
    "            \"description\": \"Real-time air temperature readings from weather stations\"\n",
    "        },\n",
    "        \"rainfall\": {\n",
    "            \"url\": \"https://api-open.data.gov.sg/v2/real-time/api/rainfall\",\n",
    "            \"description\": \"Real-time rainfall readings from weather stations\"\n",
    "        }\n",
    "    },\n",
    "    \"satellite\": {\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"API configuration loaded inline.\")\n",
    "for section, details in api_config.items():\n",
    "    if isinstance(details, dict):\n",
    "        print(f\"  • {section}: {', '.join(details.keys())}\")\n",
    "    else:\n",
    "        print(f\"  • {section}: configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c6314",
   "metadata": {},
   "source": [
    "query time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Current timestamp: 20251008T180011Z\n",
      "🕒 Historical date (2 months ago): 2025-08-10\n",
      "📁 Data will be saved to: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\n",
      "💾 Dengue data path: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\dengue\n",
      "💾 Weather data path: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\weather\n"
     ]
    }
   ],
   "source": [
    "# Set up time periods for data acquisition\n",
    "if 'project_root' not in globals():\n",
    "    raise RuntimeError(\"project_root is not defined. Run the configuration cell above first.\")\n",
    "\n",
    "# Current timestamp for file naming\n",
    "current_timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "# Calculate dates for temporal lag analysis (2 months back)\n",
    "# Research finding: 2-month lag provides better fitting model\n",
    "months_back = 2\n",
    "historical_date = (datetime.now() - timedelta(days=months_back * 30)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Data paths setup\n",
    "data_root = project_root / \"data\"\n",
    "raw_dengue_dir = data_root / \"raw\" / \"dengue\"\n",
    "raw_weather_dir = data_root / \"raw\" / \"weather\"\n",
    "\n",
    "raw_dengue_dir.mkdir(parents=True, exist_ok=True)\n",
    "(raw_weather_dir / \"temperature\").mkdir(parents=True, exist_ok=True)\n",
    "(raw_weather_dir / \"rainfall\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Current timestamp: {current_timestamp}\")\n",
    "print(f\"Historical date (2 months ago): {historical_date}\")\n",
    "print(f\"Data will be saved to: {data_root}\")\n",
    "print(f\"Dengue data path: {raw_dengue_dir}\")\n",
    "print(f\"Weather data path: {raw_weather_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f682e",
   "metadata": {},
   "source": [
    "prepare dengue cluster api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dengue cluster fetch function defined\n"
     ]
    }
   ],
   "source": [
    "# Dengue cluster data acquisition function\n",
    "def fetch_clusters(target_date: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Fetch dengue cluster data from Singapore Open Data API.\n",
    "\n",
    "    Args:\n",
    "        target_date: Optional date string in YYYY-MM-DD format.\n",
    "                    If None, fetches latest data.\n",
    "                    For temporal lag analysis, use date from 2 months ago.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw_dengue_dir.mkdir(parents=True, exist_ok=True)\n",
    "        timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "        # Add date suffix to filename if specific date requested\n",
    "        date_suffix = f\"_{target_date}\" if target_date else \"_latest\"\n",
    "        output_file = raw_dengue_dir / f\"dengue_clusters{date_suffix}_{timestamp}.json\"\n",
    "\n",
    "        # Singapore Open Data API endpoint for dengue clusters\n",
    "        dataset_id = api_config['nea']['dengue_clusters']['dataset_id']\n",
    "        base_url = api_config['nea']['dengue_clusters']['base_url']\n",
    "        url = f\"{base_url}/{dataset_id}/poll-download\"\n",
    "\n",
    "        print(f\"Fetching dengue cluster data for date: {target_date or 'latest'}\")\n",
    "\n",
    "        with httpx.Client(timeout=30.0) as client:\n",
    "            # First, get the download URL\n",
    "            response = client.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            api_response = response.json()\n",
    "            if api_response.get('code') != 0:\n",
    "                error_msg = api_response.get('errMsg', 'Unknown API error')\n",
    "                print(f\"Error code: {api_response.get('code')}, API Error: {error_msg}\")\n",
    "                raise RuntimeError(f\"API Error: {error_msg}\")\n",
    "\n",
    "            # Get the actual data URL\n",
    "            data_url = api_response['data']['url']\n",
    "            print(f\"Data URL obtained: {data_url}\")\n",
    "\n",
    "            # Fetch the actual dengue data\n",
    "            data_response = client.get(data_url)\n",
    "            data_response.raise_for_status()\n",
    "\n",
    "            # Parse and save the data\n",
    "            dengue_data = data_response.json()\n",
    "\n",
    "            # Add metadata for processing pipeline\n",
    "            metadata = {\n",
    "                \"fetch_timestamp\": timestamp,\n",
    "                \"target_date\": target_date,\n",
    "                \"api_endpoint\": url,\n",
    "                \"data_url\": data_url,\n",
    "                \"record_count\": len(dengue_data.get('features', [])) if isinstance(dengue_data, dict) else len(dengue_data) if isinstance(dengue_data, list) else 0\n",
    "            }\n",
    "\n",
    "            # Combine data with metadata\n",
    "            output_data = {\n",
    "                \"metadata\": metadata,\n",
    "                \"data\": dengue_data\n",
    "            }\n",
    "\n",
    "        output_file.write_text(json.dumps(output_data, indent=2), encoding=\"utf-8\")\n",
    "        print(f\"Dengue cluster data saved to: {output_file}\")\n",
    "        print(f\"Records fetched: {metadata['record_count']}\")\n",
    "\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        print(f\"Error code: {e.response.status_code}, HTTP Error: {e.response.text}\")\n",
    "        print(f\"Failed to fetch dengue data - HTTP {e.response.status_code}\")\n",
    "        raise\n",
    "    except httpx.TimeoutException:\n",
    "        print(\"Error code: TIMEOUT, Connection timeout - API server not responding\")\n",
    "        print(\"Failed to fetch dengue data - Connection timeout\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error code: JSON_DECODE, Invalid JSON response: {str(e)}\")\n",
    "        print(\"Failed to parse dengue data - Invalid JSON response\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error code: UNKNOWN, Unexpected error: {str(e)}\")\n",
    "        print(f\"Unexpected error in dengue data acquisition: {type(e).__name__}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5cbde",
   "metadata": {},
   "source": [
    "fetch dengue cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e540746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🦟 DENGUE CLUSTER DATA ACQUISITION ===\n",
      "\n",
      "📡 Fetching latest dengue cluster data...\n",
      "🦟 Fetching dengue cluster data for date: latest\n",
      "🔗 Data URL obtained: https://s3.ap-southeast-1.amazonaws.com/blobs.data.gov.sg/d_dbfabf16158d1b0e1c420627c0819168.geojson?AWSAccessKeyId=ASIAU7LWPY2WPPLR2GQU&Expires=1759950008&Signature=GMsCjXO5dqUm%2FOLtDrbvhNOk0i0%3D&X-Amzn-Trace-Id=Root%3D1-68e6a6a8-4f206ffe5340e86d61ef36f0%3BParent%3D217f57c3549bd948%3BSampled%3D0%3BLineage%3D1%3Affb76583%3A0&response-content-disposition=attachment%3B%20filename%3D%22DengueClustersGEOJSON.geojson%22&x-amz-security-token=IQoJb3JpZ2luX2VjECgaDmFwLXNvdXRoZWFzdC0xIkcwRQIhAM4ivIByHCSsDjVAFeIoY%2FaV9GyaY1QmedhLsBahLfLtAiBph7YzgDQRjRKB5BWAL5C3h4%2Fr35fv5tjtgzXhLT%2BhHyqzAwjB%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDM0MjIzNTI2ODc4MCIMyUokH42kTwvau4i0KocDLvUKybVtVMcLIe%2Fy3SyLIcAUUIuaczRFVanr8a4deE2wVn81sFMWZefACUgFpowoLFIiG%2FRc23UnzHySFG9wTj3ZCAi4fgqTUJBeSnp4RC7UQ1RMMYOpuUM%2FUWoMxXs1s2ghCDcwl3MhoHgqvuE%2FWfwraj54xnLM8W6nL2p4asfenYcgsbBhkRTxszygXWBuB0Yeaxg9dt5btb9kl4X8GJzSFPGtTbj06srLAcG%2BJJ78XsuEHaDpviPiC48%2BtOfAoCeqvLBKhyvCuGCCYApxFu9Cf%2By3TSaB4IG9exPzJJnjaLoDwqUOr9MHzoEUCTQVq5nPdkOdAGDw9DdZyXPPdIPjhr0Vo3wtyVXeDBsSlm%2F2FPR7hXnThtzC%2FzoBLCDUxIgmCp1LWSffXW5sdN9uIeLR1%2BxPCL4h8qpWBGyaZ4Jb9DdtZheLO8W%2Fi5wygwMfcY1iM5N4TWElnOgigQZhcKFzI9kBGQ3dPsi%2BBqnNb84KHlWc5POTM4t76gwMGRbUDs6eNeBQDDDAm5rHBjqdAcGWMiRCWcEEGzP2Fi72Ar%2FDLeCXjgUnY%2BG5Kt%2FGTJOmKiCePGffSW15VbVskWNHB0U7ksOa%2BA%2FG7mLqSK8BGsOEljQ28Oq0bw1RVDDDaz9G0onW91IrIFHpb9y1HBPOT4yRSvM%2FQdjscmHuNk7u%2FUvNh3buHWjfUz5A7QNHMZ52efbkKIMw2CTUdzYZljfwy5caBOg8r%2Bc3qJ0Km5Y%3D\n",
      "✅ Dengue cluster data saved to: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\dengue\\dengue_clusters_latest_20251008T180011Z.json\n",
      "📊 Records fetched: 4\n",
      "\n",
      "🕒 Fetching historical dengue data from 2 months ago...\n",
      "🦟 Fetching dengue cluster data for date: 2025-08-10\n",
      "🔗 Data URL obtained: https://s3.ap-southeast-1.amazonaws.com/blobs.data.gov.sg/d_dbfabf16158d1b0e1c420627c0819168.geojson?AWSAccessKeyId=ASIAU7LWPY2WKW7UXGME&Expires=1759950009&Signature=tEKOkXwJRS3loQKc75aOAwAL9uA%3D&X-Amzn-Trace-Id=Root%3D1-68e6a6a9-2d9cf63a3f4cec500a094628%3BParent%3D36780c471741ea28%3BSampled%3D0%3BLineage%3D1%3Affb76583%3A0&response-content-disposition=attachment%3B%20filename%3D%22DengueClustersGEOJSON.geojson%22&x-amz-security-token=IQoJb3JpZ2luX2VjECoaDmFwLXNvdXRoZWFzdC0xIkYwRAIgFzhfWPkiC4onxnKk4WzATk6FueDUnXJtjxPc0B426zoCIBlUu7ZM0ShoC5Kvbb6nrCZ5c%2FIDegUU7U908A4o4Z60KrMDCMP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMMzQyMjM1MjY4NzgwIgya9pHkrABFkkMAWnsqhwPs2UevSN4ZzQtho9cwMWS8OP6eeZIFb83XawSv0RcY%2FtZh93QuQr6114si2TkX3PbMGwoflCtngcoauXWS1rA%2BiY5Rub7tWf4oC7Kk%2FGKs1u2DR5VkcemWX12s9jzojgOp959Ohj27lVvMtD1V8SvGpypfmubC70DzAW2PnGL7yJLyIekgH2xM0NxHBR%2BmB9V0kgy6MU3YjM52f8Jr4gyickeVt%2BQXRoY5qklqweOkEdbzNxdzbItep7JUio0INYkhxib6foHGd4pjYWxpUu8L%2FbnZeuJ3PV%2B9xlK6yZoTEMzSlojZbcxsJGUQfxmrw9GpnqMnuqnOnGQ2ZescqRH%2B6gJj8dcxPdX5xyFZZeM71oCUCIUu2e6NTLwu6byckEAqbZ%2BGFSkujv%2FAeSkvg5A44IJueZf9bzm3sphkPPq4lePpDR4XXCsLoGr%2FjjqpXUJ7%2FpLnDKP4AFQubqBGcxwrhVEPDUYLGFNTC4OA5K4zCxEepvrlFRAtTPoQH2mkR27z14GYaICsMJTLmscGOp4BEf0Rj1zC8CQTmmOfWJ%2B5Rz6TR%2BypwiRPeyejgN9N7GlgEu3eGyXJ%2B95O4l96hH3ZVVAuURyntv%2Fk%2BgsTBrJ6lRkAsm3vPMcxVeyRtm3StKML8J5qsMKy2On8lqK%2FPoCDCXh%2Bm7pRrlyRCKHhXW3YOqDOUU2xPmOGLf2WYaIgRwUmIPM2NSb%2FzlIx9%2F9kyQV9xyHkioCK2E8vy92dO%2FU%3D\n",
      "✅ Dengue cluster data saved to: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\dengue\\dengue_clusters_2025-08-10_20251008T180012Z.json\n",
      "📊 Records fetched: 4\n",
      "\n",
      "✅ Dengue data acquisition completed!\n",
      "\n",
      "📋 Alert Level Definitions:\n",
      "   🔴 Red: High-risk area with 10 or more cases\n",
      "   🟡 Yellow: High-risk area with less than 10 cases\n",
      "   🟢 Green: No new cases, under surveillance for the next 21 days\n"
     ]
    }
   ],
   "source": [
    "# Execute dengue cluster data acquisition\n",
    "print(\"=== Dengue Cluster Data Acquisition ===\")\n",
    "\n",
    "# Fetch latest dengue data\n",
    "print(\"\\nFetching latest dengue cluster data...\")\n",
    "fetch_clusters()\n",
    "\n",
    "# Fetch historical dengue data for temporal lag analysis\n",
    "print(f\"\\nFetching historical dengue data from {months_back} months ago...\")\n",
    "fetch_clusters(historical_date)\n",
    "\n",
    "print(\"\\nDengue data acquisition completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd27a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Weather data fetch functions defined\n"
     ]
    }
   ],
   "source": [
    "# Weather data acquisition functions\n",
    "def fetch_air_temperature(target_date: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Fetch air temperature data from Singapore Open Data API.\n",
    "\n",
    "    Args:\n",
    "        target_date: Optional date string in YYYY-MM-DD or YYYY-MM-DDTHH:MM:SS format.\n",
    "                    If None, fetches latest data.\n",
    "                    For temporal lag analysis, use date from 2 months ago.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp_dir = raw_weather_dir / \"temperature\"\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "        date_suffix = f\"_{target_date}\" if target_date else \"_latest\"\n",
    "        output_file = temp_dir / f\"air_temperature{date_suffix}_{timestamp}.json\"\n",
    "\n",
    "        url = api_config['weather']['air_temperature']['url']\n",
    "\n",
    "        # Add date parameter if specified\n",
    "        params = {}\n",
    "        if target_date:\n",
    "            params['date'] = target_date\n",
    "            print(f\"Fetching air temperature data for date: {target_date}\")\n",
    "        else:\n",
    "            print(\"Fetching latest air temperature data...\")\n",
    "\n",
    "        with httpx.Client(timeout=30.0) as client:\n",
    "            response = client.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            temp_data = response.json()\n",
    "\n",
    "            # Add metadata for processing pipeline\n",
    "            metadata = {\n",
    "                \"fetch_timestamp\": timestamp,\n",
    "                \"target_date\": target_date,\n",
    "                \"api_endpoint\": url,\n",
    "                \"station_count\": len(temp_data.get('data', {}).get('stations', [])) if isinstance(temp_data, dict) else 0\n",
    "            }\n",
    "\n",
    "            # Combine data with metadata\n",
    "            output_data = {\n",
    "                \"metadata\": metadata,\n",
    "                \"data\": temp_data\n",
    "            }\n",
    "\n",
    "        output_file.write_text(json.dumps(output_data, indent=2), encoding=\"utf-8\")\n",
    "        print(f\"Air temperature data saved to: {output_file}\")\n",
    "        print(f\"Weather stations: {metadata['station_count']}\")\n",
    "\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        print(f\"Error code: {e.response.status_code}, HTTP Error: {e.response.text}\")\n",
    "        print(f\"Failed to fetch temperature data - HTTP {e.response.status_code}\")\n",
    "        if e.response.status_code == 404:\n",
    "            print(\"Tip: Weather data might not be available for the requested date\")\n",
    "        raise\n",
    "    except httpx.TimeoutException:\n",
    "        print(\"Error code: TIMEOUT, Connection timeout - API server not responding\")\n",
    "        print(\"Failed to fetch temperature data - Connection timeout\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error code: JSON_DECODE, Invalid JSON response: {str(e)}\")\n",
    "        print(\"Failed to parse temperature data - Invalid JSON response\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error code: UNKNOWN, Unexpected error: {str(e)}\")\n",
    "        print(f\"Unexpected error in temperature data acquisition: {type(e).__name__}\")\n",
    "        raise\n",
    "\n",
    "def fetch_rainfall(target_date: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Fetch rainfall data from Singapore Open Data API.\n",
    "\n",
    "    Args:\n",
    "        target_date: Optional date string in YYYY-MM-DD or YYYY-MM-DDTHH:MM:SS format.\n",
    "                    If None, fetches latest data.\n",
    "                    For temporal lag analysis, use date from 2 months ago.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rainfall_dir = raw_weather_dir / \"rainfall\"\n",
    "        rainfall_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "        date_suffix = f\"_{target_date}\" if target_date else \"_latest\"\n",
    "        output_file = rainfall_dir / f\"rainfall{date_suffix}_{timestamp}.json\"\n",
    "\n",
    "        url = api_config['weather']['rainfall']['url']\n",
    "\n",
    "        # Add date parameter if specified\n",
    "        params = {}\n",
    "        if target_date:\n",
    "            params['date'] = target_date\n",
    "            print(f\"Fetching rainfall data for date: {target_date}\")\n",
    "        else:\n",
    "            print(\"Fetching latest rainfall data...\")\n",
    "\n",
    "        with httpx.Client(timeout=30.0) as client:\n",
    "            response = client.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            rainfall_data = response.json()\n",
    "\n",
    "            # Add metadata for processing pipeline\n",
    "            metadata = {\n",
    "                \"fetch_timestamp\": timestamp,\n",
    "                \"target_date\": target_date,\n",
    "                \"api_endpoint\": url,\n",
    "                \"station_count\": len(rainfall_data.get('data', {}).get('stations', [])) if isinstance(rainfall_data, dict) else 0\n",
    "            }\n",
    "\n",
    "            # Combine data with metadata\n",
    "            output_data = {\n",
    "                \"metadata\": metadata,\n",
    "                \"data\": rainfall_data\n",
    "            }\n",
    "\n",
    "        output_file.write_text(json.dumps(output_data, indent=2), encoding=\"utf-8\")\n",
    "        print(f\"Rainfall data saved to: {output_file}\")\n",
    "        print(f\"Weather stations: {metadata['station_count']}\")\n",
    "\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        print(f\"Error code: {e.response.status_code}, HTTP Error: {e.response.text}\")\n",
    "        print(f\"Failed to fetch rainfall data - HTTP {e.response.status_code}\")\n",
    "        if e.response.status_code == 404:\n",
    "            print(\"Tip: Rainfall data might not be available for the requested date\")\n",
    "        raise\n",
    "    except httpx.TimeoutException:\n",
    "        print(\"Error code: TIMEOUT, Connection timeout - API server not responding\")\n",
    "        print(\"Failed to fetch rainfall data - Connection timeout\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error code: JSON_DECODE, Invalid JSON response: {str(e)}\")\n",
    "        print(\"Failed to parse rainfall data - Invalid JSON response\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error code: UNKNOWN, Unexpected error: {str(e)}\")\n",
    "        print(f\"Unexpected error in rainfall data acquisition: {type(e).__name__}\")\n",
    "        raise\n",
    "\n",
    "print(\"Weather data fetch functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21b9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined weather fetch function defined\n"
     ]
    }
   ],
   "source": [
    "# Combined weather data acquisition function\n",
    "def fetch_weather(target_date: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Fetch both air temperature and rainfall data.\n",
    "\n",
    "    Args:\n",
    "        target_date: Optional date string for temporal lag analysis.\n",
    "                    Format: YYYY-MM-DD or YYYY-MM-DDTHH:MM:SS\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw_weather_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(\"=== Weather Data Acquisition ===\")\n",
    "        if target_date:\n",
    "            print(f\"Target date: {target_date} (for temporal lag analysis)\")\n",
    "        else:\n",
    "            print(\"Fetching latest weather data...\")\n",
    "\n",
    "        fetch_air_temperature(target_date)\n",
    "        fetch_rainfall(target_date)\n",
    "\n",
    "        print(\"Weather data collection completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in weather data acquisition: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ee58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🌤️  WEATHER DATA ACQUISITION ===\n",
      "\n",
      "📡 Fetching latest weather data...\n",
      "📅 Fetching latest weather data...\n",
      "🌡️  Fetching latest air temperature data...\n",
      "✅ Air temperature data saved to: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\weather\\temperature\\air_temperature_latest_20251008T180013Z.json\n",
      "📊 Weather stations: 11\n",
      "🌧️  Fetching latest rainfall data...\n",
      "✅ Rainfall data saved to: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\weather\\rainfall\\rainfall_latest_20251008T180014Z.json\n",
      "📊 Weather stations: 55\n",
      "✅ Weather data collection completed successfully\n",
      "\n",
      "🕒 Fetching historical weather data from 2 months ago...\n",
      "📚 Research note: 2-month lag provides better fitting model for dengue prediction\n",
      "🕒 Target date: 2025-08-10 (for temporal lag analysis)\n",
      "🌡️  Fetching air temperature data for date: 2025-08-10\n",
      "✅ Air temperature data saved to: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\weather\\temperature\\air_temperature_2025-08-10_20251008T180015Z.json\n",
      "📊 Weather stations: 13\n",
      "🌧️  Fetching rainfall data for date: 2025-08-10\n",
      "✅ Rainfall data saved to: D:\\MY\\2025-26-1\\GISDATA\\GE5219-Dengue\\data\\raw\\weather\\rainfall\\rainfall_2025-08-10_20251008T180017Z.json\n",
      "📊 Weather stations: 58\n",
      "✅ Weather data collection completed successfully\n",
      "\n",
      "✅ Weather data acquisition completed!\n",
      "\n",
      "📋 API Information:\n",
      "   🌡️  Air Temperature: Updated every minute from NEA weather stations (°C)\n",
      "   🌧️  Rainfall: Updated every 5 minutes from NEA weather stations (mm)\n",
      "   📅 Date format: YYYY-MM-DD or YYYY-MM-DDTHH:MM:SS (SGT)\n"
     ]
    }
   ],
   "source": [
    "# Execute weather data acquisition\n",
    "print(\"=== Weather Data Acquisition ===\")\n",
    "\n",
    "# Fetch latest weather data\n",
    "print(\"\\nFetching latest weather data...\")\n",
    "fetch_weather()\n",
    "\n",
    "# Fetch historical weather data for temporal lag analysis\n",
    "print(f\"\\nFetching historical weather data from {months_back} months ago...\")\n",
    "print(\"Research note: 2-month lag provides better fitting model for dengue prediction\")\n",
    "fetch_weather(historical_date)\n",
    "\n",
    "print(\"\\nWeather data acquisition completed!\")\n",
    "print(\"\\nAPI Information:\")\n",
    "print(\"   Air Temperature: Updated every minute from NEA weather stations (°C)\")\n",
    "print(\"   Rainfall: Updated every 5 minutes from NEA weather stations (mm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8df992",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (752277746.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    > Static geographical boundaries for Singapore subzones\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Load Subzone Boundaries\n",
    "> Static geographical boundaries for Singapore subzones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for subzone boundaries loading\n",
    "# Data source: https://data.gov.sg/datasets?query=Boundary&page=1&sidebar=false&resultId=d_8594ae9ff96d0c708bc2af633048edfb\n",
    "\n",
    "boundaries_dir = data_root / \"raw\" / \"boundaries\"\n",
    "boundaries_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Subzone boundaries loading - TO BE IMPLEMENTED\")\n",
    "print(f\"Boundaries will be saved to: {boundaries_dir}\")\n",
    "print(\"Data source: Singapore subzone boundary polygons\")\n",
    "print(\"Purpose: Spatial aggregation and risk zone mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166ef08",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "### Load Population by Subzone\n",
    "> Population density data for risk calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for population data loading\n",
    "# Data source: https://data.gov.sg/datasets/d_e7ae90176a68945837ad67892b898466/view\n",
    "\n",
    "population_dir = data_root / \"raw\" / \"population\"\n",
    "population_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Population data loading - TO BE IMPLEMENTED\")\n",
    "print(f\"Population data will be saved to: {population_dir}\")\n",
    "print(\"Data source: Population count by Singapore subzones\")\n",
    "print(\"Purpose: Calculate population density for risk modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6da176",
   "metadata": {},
   "source": [
    "### NDVI Satellite Data\n",
    "> Vegetation density for environmental risk factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c977570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for NDVI satellite data acquisition\n",
    "# Note: Sentinel-2 imagery processing will be implemented in create_ndvi.py\n",
    "\n",
    "satellite_dir = data_root / \"raw\" / \"satellite\"\n",
    "satellite_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"NDVI satellite data acquisition - TO BE IMPLEMENTED\")\n",
    "print(f\"Satellite data will be saved to: {satellite_dir}\")\n",
    "print(\"Data source: Sentinel-2 or other satellite imagery\")\n",
    "print(\"Purpose: Calculate vegetation density (NDVI) for environmental risk factors\")\n",
    "print(\"Note: Requires satellite imagery API credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a19a36",
   "metadata": {},
   "source": [
    "### Data Acquisition Summary\n",
    "> Review collected data and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d0159",
   "metadata": {},
   "source": [
    "## Processing & Cleaning\n",
    "> Cleaning data and applying temporal lag\n",
    "\n",
    "- calculate_population_density.py\n",
    "- apply_temporal_lag.py\n",
    "- interpolate_surfaces.py\n",
    "- create_ndvi.py\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b3ff2",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a2277f7",
   "metadata": {},
   "source": [
    "## Analysis (Prepare Data)\n",
    "- Aggregation and risk calculation\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278b8d6",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6b672b2",
   "metadata": {},
   "source": [
    "## Weighted Risk Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139f75b",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4892502",
   "metadata": {},
   "source": [
    "## Visualization & Deployment\n",
    "> Creating maps and statistical visualizations\n",
    "\n",
    "- app_config\n",
    "- /visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e8512",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e6610bb",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde07ba",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "017d4097",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
